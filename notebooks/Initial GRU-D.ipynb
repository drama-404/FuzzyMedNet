{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T10:56:52.596436700Z",
     "start_time": "2023-10-31T10:56:52.471351300Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T10:56:58.379711200Z",
     "start_time": "2023-10-31T10:56:52.533931600Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "from mmd_grud_utils2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T10:56:58.395581Z",
     "start_time": "2023-10-31T10:56:58.379711200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x16e6e892f30>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_FILEPATH     = '../data/all_hourly_data.h5'\n",
    "# RAW_DATA_FILEPATH = '/scratch/mmd/mimic_data/final/nogrouping_5/all_hourly_data.h5'\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T10:56:58.455218400Z",
     "start_time": "2023-10-31T10:56:58.395581Z"
    }
   },
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T10:57:37.708737300Z",
     "start_time": "2023-10-31T10:56:58.408339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 19.8 s\n",
      "Wall time: 38.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "# data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T10:57:37.824421200Z",
     "start_time": "2023-10-31T10:57:37.603789700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LEVEL2                                 alanine aminotransferase             \\\nAggregation Function                                      count  mean  std   \nsubject_id hadm_id icustay_id hours_in                                       \n3          145834  211552     0                             2.0  25.0  0.0   \n                              1                             0.0   NaN  NaN   \n                              2                             0.0   NaN  NaN   \n                              3                             0.0   NaN  NaN   \n                              4                             0.0   NaN  NaN   \n\nLEVEL2                                 albumin           albumin ascites       \\\nAggregation Function                     count mean  std           count mean   \nsubject_id hadm_id icustay_id hours_in                                          \n3          145834  211552     0            2.0  1.8  0.0             0.0  NaN   \n                              1            0.0  NaN  NaN             0.0  NaN   \n                              2            0.0  NaN  NaN             0.0  NaN   \n                              3            0.0  NaN  NaN             0.0  NaN   \n                              4            0.0  NaN  NaN             0.0  NaN   \n\nLEVEL2                                     albumin pleural  ...  \\\nAggregation Function                   std           count  ...   \nsubject_id hadm_id icustay_id hours_in                      ...   \n3          145834  211552     0        NaN             0.0  ...   \n                              1        NaN             0.0  ...   \n                              2        NaN             0.0  ...   \n                              3        NaN             0.0  ...   \n                              4        NaN             0.0  ...   \n\nLEVEL2                                 white blood cell count  \\\nAggregation Function                                      std   \nsubject_id hadm_id icustay_id hours_in                          \n3          145834  211552     0                      4.012837   \n                              1                           NaN   \n                              2                           NaN   \n                              3                           NaN   \n                              4                           NaN   \n\nLEVEL2                                 white blood cell count urine           \\\nAggregation Function                                          count mean std   \nsubject_id hadm_id icustay_id hours_in                                         \n3          145834  211552     0                                 0.0  NaN NaN   \n                              1                                 0.0  NaN NaN   \n                              2                                 0.0  NaN NaN   \n                              3                                 0.0  NaN NaN   \n                              4                                 0.0  NaN NaN   \n\nLEVEL2                                    ph                 ph urine           \nAggregation Function                   count  mean       std    count mean std  \nsubject_id hadm_id icustay_id hours_in                                          \n3          145834  211552     0          9.0  7.40  0.147733      1.0  5.0 NaN  \n                              1          0.0   NaN       NaN      0.0  NaN NaN  \n                              2          3.0  7.26  0.000000      0.0  NaN NaN  \n                              3          0.0   NaN       NaN      0.0  NaN NaN  \n                              4          0.0   NaN       NaN      0.0  NaN NaN  \n\n[5 rows x 312 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>LEVEL2</th>\n      <th colspan=\"3\" halign=\"left\">alanine aminotransferase</th>\n      <th colspan=\"3\" halign=\"left\">albumin</th>\n      <th colspan=\"3\" halign=\"left\">albumin ascites</th>\n      <th>albumin pleural</th>\n      <th>...</th>\n      <th>white blood cell count</th>\n      <th colspan=\"3\" halign=\"left\">white blood cell count urine</th>\n      <th colspan=\"3\" halign=\"left\">ph</th>\n      <th colspan=\"3\" halign=\"left\">ph urine</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>Aggregation Function</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>...</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n      <th>count</th>\n      <th>mean</th>\n      <th>std</th>\n    </tr>\n    <tr>\n      <th>subject_id</th>\n      <th>hadm_id</th>\n      <th>icustay_id</th>\n      <th>hours_in</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">3</th>\n      <th rowspan=\"5\" valign=\"top\">145834</th>\n      <th rowspan=\"5\" valign=\"top\">211552</th>\n      <th>0</th>\n      <td>2.0</td>\n      <td>25.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.012837</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9.0</td>\n      <td>7.40</td>\n      <td>0.147733</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>7.26</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 312 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T10:57:37.824421200Z",
     "start_time": "2023-10-31T10:57:37.693115100Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_full_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T10:57:38.435728800Z",
     "start_time": "2023-10-31T10:57:37.693115100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                              gender              ethnicity        age  \\\nsubject_id hadm_id icustay_id                                            \n3          145834  211552          M                  WHITE  76.526792   \n4          185777  294638          F                  WHITE  47.845047   \n6          107064  228232          F                  WHITE  65.942297   \n9          150750  220597          M  UNKNOWN/NOT SPECIFIED  41.790228   \n11         194540  229441          F                  WHITE  50.148295   \n\n                              insurance           admittime  \\\nsubject_id hadm_id icustay_id                                 \n3          145834  211552      Medicare 2101-10-20 19:08:00   \n4          185777  294638       Private 2191-03-16 00:28:00   \n6          107064  228232      Medicare 2175-05-30 07:15:00   \n9          150750  220597      Medicaid 2149-11-09 13:06:00   \n11         194540  229441       Private 2178-04-16 06:18:00   \n\n                                            diagnosis_at_admission  \\\nsubject_id hadm_id icustay_id                                        \n3          145834  211552                              HYPOTENSION   \n4          185777  294638      FEVER,DEHYDRATION,FAILURE TO THRIVE   \n6          107064  228232                CHRONIC RENAL FAILURE/SDA   \n9          150750  220597                          HEMORRHAGIC CVA   \n11         194540  229441                               BRAIN MASS   \n\n                                        dischtime         discharge_location  \\\nsubject_id hadm_id icustay_id                                                  \n3          145834  211552     2101-10-31 13:58:00                        SNF   \n4          185777  294638     2191-03-23 18:41:00  HOME WITH HOME IV PROVIDR   \n6          107064  228232     2175-06-15 16:00:00           HOME HEALTH CARE   \n9          150750  220597     2149-11-14 10:15:00               DEAD/EXPIRED   \n11         194540  229441     2178-05-11 19:00:00           HOME HEALTH CARE   \n\n                               fullcode_first  dnr_first  ...  \\\nsubject_id hadm_id icustay_id                             ...   \n3          145834  211552                 1.0        0.0  ...   \n4          185777  294638                 1.0        0.0  ...   \n6          107064  228232                 1.0        0.0  ...   \n9          150750  220597                 1.0        0.0  ...   \n11         194540  229441                 1.0        0.0  ...   \n\n                                          outtime   los_icu admission_type  \\\nsubject_id hadm_id icustay_id                                                \n3          145834  211552     2101-10-26 20:43:09  6.064560      EMERGENCY   \n4          185777  294638     2191-03-17 16:46:31  1.678472      EMERGENCY   \n6          107064  228232     2175-06-03 13:39:54  3.672917       ELECTIVE   \n9          150750  220597     2149-11-14 20:52:14  5.323056      EMERGENCY   \n11         194540  229441     2178-04-17 20:21:05  1.584410      EMERGENCY   \n\n                               first_careunit  mort_icu  mort_hosp  \\\nsubject_id hadm_id icustay_id                                        \n3          145834  211552                MICU         0          0   \n4          185777  294638                MICU         0          0   \n6          107064  228232                SICU         0          0   \n9          150750  220597                MICU         1          1   \n11         194540  229441                SICU         0          0   \n\n                              hospital_expire_flag hospstay_seq  \\\nsubject_id hadm_id icustay_id                                     \n3          145834  211552                        0            1   \n4          185777  294638                        0            1   \n6          107064  228232                        0            1   \n9          150750  220597                        1            1   \n11         194540  229441                        0            1   \n\n                              readmission_30  max_hours  \nsubject_id hadm_id icustay_id                            \n3          145834  211552                  0        145  \n4          185777  294638                  0         40  \n6          107064  228232                  0         88  \n9          150750  220597                  0        127  \n11         194540  229441                  0         38  \n\n[5 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>gender</th>\n      <th>ethnicity</th>\n      <th>age</th>\n      <th>insurance</th>\n      <th>admittime</th>\n      <th>diagnosis_at_admission</th>\n      <th>dischtime</th>\n      <th>discharge_location</th>\n      <th>fullcode_first</th>\n      <th>dnr_first</th>\n      <th>...</th>\n      <th>outtime</th>\n      <th>los_icu</th>\n      <th>admission_type</th>\n      <th>first_careunit</th>\n      <th>mort_icu</th>\n      <th>mort_hosp</th>\n      <th>hospital_expire_flag</th>\n      <th>hospstay_seq</th>\n      <th>readmission_30</th>\n      <th>max_hours</th>\n    </tr>\n    <tr>\n      <th>subject_id</th>\n      <th>hadm_id</th>\n      <th>icustay_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <th>145834</th>\n      <th>211552</th>\n      <td>M</td>\n      <td>WHITE</td>\n      <td>76.526792</td>\n      <td>Medicare</td>\n      <td>2101-10-20 19:08:00</td>\n      <td>HYPOTENSION</td>\n      <td>2101-10-31 13:58:00</td>\n      <td>SNF</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2101-10-26 20:43:09</td>\n      <td>6.064560</td>\n      <td>EMERGENCY</td>\n      <td>MICU</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>145</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <th>185777</th>\n      <th>294638</th>\n      <td>F</td>\n      <td>WHITE</td>\n      <td>47.845047</td>\n      <td>Private</td>\n      <td>2191-03-16 00:28:00</td>\n      <td>FEVER,DEHYDRATION,FAILURE TO THRIVE</td>\n      <td>2191-03-23 18:41:00</td>\n      <td>HOME WITH HOME IV PROVIDR</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2191-03-17 16:46:31</td>\n      <td>1.678472</td>\n      <td>EMERGENCY</td>\n      <td>MICU</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <th>107064</th>\n      <th>228232</th>\n      <td>F</td>\n      <td>WHITE</td>\n      <td>65.942297</td>\n      <td>Medicare</td>\n      <td>2175-05-30 07:15:00</td>\n      <td>CHRONIC RENAL FAILURE/SDA</td>\n      <td>2175-06-15 16:00:00</td>\n      <td>HOME HEALTH CARE</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2175-06-03 13:39:54</td>\n      <td>3.672917</td>\n      <td>ELECTIVE</td>\n      <td>SICU</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <th>150750</th>\n      <th>220597</th>\n      <td>M</td>\n      <td>UNKNOWN/NOT SPECIFIED</td>\n      <td>41.790228</td>\n      <td>Medicaid</td>\n      <td>2149-11-09 13:06:00</td>\n      <td>HEMORRHAGIC CVA</td>\n      <td>2149-11-14 10:15:00</td>\n      <td>DEAD/EXPIRED</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2149-11-14 20:52:14</td>\n      <td>5.323056</td>\n      <td>EMERGENCY</td>\n      <td>MICU</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>127</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <th>194540</th>\n      <th>229441</th>\n      <td>F</td>\n      <td>WHITE</td>\n      <td>50.148295</td>\n      <td>Private</td>\n      <td>2178-04-16 06:18:00</td>\n      <td>BRAIN MASS</td>\n      <td>2178-05-11 19:00:00</td>\n      <td>HOME HEALTH CARE</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2178-04-17 20:21:05</td>\n      <td>1.584410</td>\n      <td>EMERGENCY</td>\n      <td>SICU</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T10:57:38.435728800Z",
     "start_time": "2023-10-31T10:57:37.755132200Z"
    }
   },
   "outputs": [],
   "source": [
    "def simple_imputer(df):\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "    if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "    \n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "    \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "    \n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "    \n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "    \n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T10:59:03.785620700Z",
     "start_time": "2023-10-31T10:57:37.777542300Z"
    }
   },
   "outputs": [],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "\n",
    "lvl2 = data_full_lvl2[\n",
    "    (data_full_lvl2.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (data_full_lvl2.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] \n",
    "\n",
    "# raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "lvl2_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "# assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]\n",
    "\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, Ys)\n",
    "]\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "# raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "\n",
    "# raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "# raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "# raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T11:12:17.967846100Z",
     "start_time": "2023-10-31T10:59:03.785620700Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kisse\\AppData\\Local\\Temp\\ipykernel_13600\\2730890864.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
      "C:\\Users\\kisse\\AppData\\Local\\Temp\\ipykernel_13600\\2730890864.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
      "C:\\Users\\kisse\\AppData\\Local\\Temp\\ipykernel_13600\\2730890864.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "lvl2_train, lvl2_dev, lvl2_test = [\n",
    "    simple_imputer(df) for df in (lvl2_train, lvl2_dev, lvl2_test)\n",
    "]\n",
    "lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        lvl2_train, lvl2_dev, lvl2_test\n",
    "    )\n",
    "]\n",
    "\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:12:18.085415600Z",
     "start_time": "2023-10-31T11:12:18.035684Z"
    }
   },
   "outputs": [],
   "source": [
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)\n",
    "[(Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (Ys,)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:12:18.118933600Z",
     "start_time": "2023-10-31T11:12:18.078420100Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "\n",
    "GRU_D_dist = DictDist({\n",
    "    'cell_size': ss.randint(50, 75),\n",
    "    'hidden_size': ss.randint(65, 95), \n",
    "    'learning_rate': ss.uniform(2e-3, 1e-1),\n",
    "    'num_epochs': ss.randint(15, 150),\n",
    "    'patience': ss.randint(3, 7),\n",
    "    'batch_size': ss.randint(35, 65),\n",
    "    'early_stop_frac': ss.uniform(0.05, 0.1),\n",
    "    'seed': ss.randint(1, 10000),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "GRU_D_hyperparams_list = GRU_D_dist.rvs(N)\n",
    "\n",
    "# with open('/scratch/mmd/extraction_baselines_gru-d.pkl', mode='rb') as f: results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-31T11:12:18.124059Z",
     "start_time": "2023-10-31T11:12:18.118933600Z"
    }
   },
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "for i, h in enumerate(GRU_D_hyperparams_list):\n",
    "    GRU_D_hyperparams_list[i]['batch_size'] = int(GRU_D_hyperparams_list[i]['batch_size'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:18:03.756495100Z",
     "start_time": "2023-10-31T11:18:03.740410600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'cell_size': 55,\n  'hidden_size': 66,\n  'learning_rate': 0.07052195003967596,\n  'num_epochs': 22,\n  'patience': 6,\n  'batch_size': 60,\n  'early_stop_frac': 0.051828827734419186,\n  'seed': 9496},\n {'cell_size': 61,\n  'hidden_size': 77,\n  'learning_rate': 0.022445224973151746,\n  'num_epochs': 78,\n  'patience': 5,\n  'batch_size': 38,\n  'early_stop_frac': 0.12501443149449676,\n  'seed': 3429},\n {'cell_size': 62,\n  'hidden_size': 72,\n  'learning_rate': 0.08981174363909455,\n  'num_epochs': 76,\n  'patience': 4,\n  'batch_size': 39,\n  'early_stop_frac': 0.14888610889064946,\n  'seed': 156},\n {'cell_size': 58,\n  'hidden_size': 78,\n  'learning_rate': 0.004738759319792616,\n  'num_epochs': 37,\n  'patience': 3,\n  'batch_size': 59,\n  'early_stop_frac': 0.12481656543798395,\n  'seed': 4410},\n {'cell_size': 59,\n  'hidden_size': 93,\n  'learning_rate': 0.06904675101784023,\n  'num_epochs': 72,\n  'patience': 5,\n  'batch_size': 52,\n  'early_stop_frac': 0.07804439920644052,\n  'seed': 649},\n {'cell_size': 61,\n  'hidden_size': 71,\n  'learning_rate': 0.0437304802367127,\n  'num_epochs': 16,\n  'patience': 6,\n  'batch_size': 46,\n  'early_stop_frac': 0.12892793284514886,\n  'seed': 9505},\n {'cell_size': 55,\n  'hidden_size': 90,\n  'learning_rate': 0.05786898284457517,\n  'num_epochs': 143,\n  'patience': 6,\n  'batch_size': 47,\n  'early_stop_frac': 0.06032260065776421,\n  'seed': 7587},\n {'cell_size': 65,\n  'hidden_size': 83,\n  'learning_rate': 0.016038693859523376,\n  'num_epochs': 75,\n  'patience': 5,\n  'batch_size': 61,\n  'early_stop_frac': 0.09478935261759053,\n  'seed': 1680},\n {'cell_size': 50,\n  'hidden_size': 85,\n  'learning_rate': 0.021810148908487884,\n  'num_epochs': 23,\n  'patience': 4,\n  'batch_size': 55,\n  'early_stop_frac': 0.14085955030930958,\n  'seed': 7256},\n {'cell_size': 66,\n  'hidden_size': 70,\n  'learning_rate': 0.08207445686755367,\n  'num_epochs': 130,\n  'patience': 4,\n  'batch_size': 51,\n  'early_stop_frac': 0.07936141483736796,\n  'seed': 7962}]"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GRU_D_hyperparams_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T12:39:50.247614800Z",
     "start_time": "2023-10-31T12:39:50.216053900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T11:22:28.147312900Z",
     "start_time": "2023-10-31T11:18:22.894732200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model GRU-D on target mort_icu with representation lvl2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kisse\\OneDrive\\Documents\\GitHub\\FuzzyMedNet\\notebooks\\mmd_grud_utils2.py:13: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  return np.dstack((df.loc[idx[:,:,:,i], :].values for i in sorted(set(df.index.get_level_values('hours_in')))))\n",
      "C:\\Users\\kisse\\AppData\\Local\\Temp\\ipykernel_13600\\1457725132.py:12: RuntimeWarning: Mean of empty slice\n",
      "  X_mean = np.nanmean(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On sample 1 / 10 (hyperparams = {'cell_size': 55, 'hidden_size': 66, 'learning_rate': 0.07052195003967596, 'num_epochs': 22, 'patience': 6, 'batch_size': 60, 'early_stop_frac': 0.051828827734419186, 'seed': 9496})\n",
      "Model Structure:  GRUD(\n",
      "  (zl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (rl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (hl): Linear(in_features=274, out_features=66, bias=True)\n",
      "  (gamma_x_l): FilterLinear(in_features=104, out_features=104, bias=True)\n",
      "  (gamma_h_l): Linear(in_features=104, out_features=66, bias=True)\n",
      "  (fc): Linear(in_features=66, out_features=2, bias=True)\n",
      "  (bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (drop): Dropout(p=0.5, inplace=False)\n",
      ")\n",
      "Start Training ... \n",
      "Output type dermined by the model\n",
      "Epoch: 0, train_loss: nan, valid_loss: nan, time: [33.52], best model: 1\n",
      "Epoch: 1, train_loss: nan, valid_loss: nan, time: [32.36], best model: 0\n",
      "Epoch: 2, train_loss: nan, valid_loss: nan, time: [32.59], best model: 0\n",
      "Epoch: 3, train_loss: nan, valid_loss: nan, time: [32.68], best model: 0\n",
      "Epoch: 4, train_loss: nan, valid_loss: nan, time: [32.61], best model: 0\n",
      "Epoch: 5, train_loss: nan, valid_loss: nan, time: [32.78], best model: 0\n",
      "Early Stopped at Epoch: 6\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 73\u001B[0m\n\u001B[0;32m     71\u001B[0m probabilities_dev \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(probabilities_dev)[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     72\u001B[0m labels_dev        \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mconcatenate(labels_dev)\n\u001B[1;32m---> 73\u001B[0m s \u001B[38;5;241m=\u001B[39m roc_auc_score(labels_dev, probabilities_dev)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m s \u001B[38;5;241m>\u001B[39m best_s:\n\u001B[0;32m     75\u001B[0m     best_s, best_hyperparams \u001B[38;5;241m=\u001B[39m s, hyperparams\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    205\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m    207\u001B[0m         skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m    208\u001B[0m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m    209\u001B[0m         )\n\u001B[0;32m    210\u001B[0m     ):\n\u001B[1;32m--> 211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    212\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    213\u001B[0m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[0;32m    214\u001B[0m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m     msg \u001B[38;5;241m=\u001B[39m re\u001B[38;5;241m.\u001B[39msub(\n\u001B[0;32m    218\u001B[0m         \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mw+ must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    219\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must be\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    220\u001B[0m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[0;32m    221\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:605\u001B[0m, in \u001B[0;36mroc_auc_score\u001B[1;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001B[0m\n\u001B[0;32m    603\u001B[0m y_type \u001B[38;5;241m=\u001B[39m type_of_target(y_true, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my_true\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    604\u001B[0m y_true \u001B[38;5;241m=\u001B[39m check_array(y_true, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m--> 605\u001B[0m y_score \u001B[38;5;241m=\u001B[39m check_array(y_score, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    607\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmulticlass\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m    608\u001B[0m     y_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbinary\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m y_score\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[0;32m    609\u001B[0m ):\n\u001B[0;32m    610\u001B[0m     \u001B[38;5;66;03m# do not support partial ROC computation for multiclass\u001B[39;00m\n\u001B[0;32m    611\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_fpr \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m max_fpr \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1.0\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:959\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    953\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    954\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with dim \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m expected <= 2.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    955\u001B[0m             \u001B[38;5;241m%\u001B[39m (array\u001B[38;5;241m.\u001B[39mndim, estimator_name)\n\u001B[0;32m    956\u001B[0m         )\n\u001B[0;32m    958\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m force_all_finite:\n\u001B[1;32m--> 959\u001B[0m         _assert_all_finite(\n\u001B[0;32m    960\u001B[0m             array,\n\u001B[0;32m    961\u001B[0m             input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    962\u001B[0m             estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    963\u001B[0m             allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    964\u001B[0m         )\n\u001B[0;32m    966\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    967\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m _num_samples(array)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:124\u001B[0m, in \u001B[0;36m_assert_all_finite\u001B[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m first_pass_isfinite:\n\u001B[0;32m    122\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m _assert_all_finite_element_wise(\n\u001B[0;32m    125\u001B[0m     X,\n\u001B[0;32m    126\u001B[0m     xp\u001B[38;5;241m=\u001B[39mxp,\n\u001B[0;32m    127\u001B[0m     allow_nan\u001B[38;5;241m=\u001B[39mallow_nan,\n\u001B[0;32m    128\u001B[0m     msg_dtype\u001B[38;5;241m=\u001B[39mmsg_dtype,\n\u001B[0;32m    129\u001B[0m     estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    130\u001B[0m     input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    131\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:173\u001B[0m, in \u001B[0;36m_assert_all_finite_element_wise\u001B[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m estimator_name \u001B[38;5;129;01mand\u001B[39;00m input_name \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m has_nan_error:\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;66;03m# Improve the error message on how to handle missing values in\u001B[39;00m\n\u001B[0;32m    158\u001B[0m     \u001B[38;5;66;03m# scikit-learn.\u001B[39;00m\n\u001B[0;32m    159\u001B[0m     msg_err \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m    160\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m does not accept missing values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    161\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    171\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m#estimators-that-handle-nan-values\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    172\u001B[0m     )\n\u001B[1;32m--> 173\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg_err)\n",
      "\u001B[1;31mValueError\u001B[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "model_name       = 'GRU-D'\n",
    "hyperparams_list = GRU_D_hyperparams_list\n",
    "RERUN            = False\n",
    "if model_name not in results: results[model_name] = {}\n",
    "for t in ['mort_icu', 'los_3', 'mort_hosp', 'los_7']:\n",
    "    if t not in results[model_name]: results[model_name][t] = {}\n",
    "    for n, X_train, X_dev, X_test in (\n",
    "        ('lvl2', lvl2_train, lvl2_dev, lvl2_test),\n",
    "#         ('raw', raw_train, raw_dev, raw_test)\n",
    "    ):\n",
    "        print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        X_mean = np.nanmean(\n",
    "            to_3D_tensor(\n",
    "                X_train.loc[:, pd.IndexSlice[:, 'mean']] * \n",
    "                np.where((X_train.loc[:, pd.IndexSlice[:, 'mask']] == 1).values, 1, np.NaN)\n",
    "            ),\n",
    "            axis=0, keepdims=True\n",
    "        ).transpose([0, 2, 1])\n",
    "        base_params = {'X_mean': X_mean, 'output_last': True, 'input_size': X_mean.shape[2]}\n",
    "    \n",
    "        if n in results[model_name][t]:\n",
    "            if not RERUN: \n",
    "                print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                print(results[model_name][t][n])\n",
    "                continue\n",
    "            best_s, best_hyperparams = results[model_name][t][n][-1], results[model_name][t][n][1]\n",
    "            print(\"Loading best hyperparams\", best_hyperparams)\n",
    "        else:\n",
    "            best_s, best_hyperparams = -np.Inf, None\n",
    "            for i, hyperparams in enumerate(hyperparams_list):\n",
    "                print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "\n",
    "                early_stop_frac,batch_size,seed = [hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "\n",
    "                np.random.seed(seed)\n",
    "                all_train_subjects = list(\n",
    "                    np.random.permutation(Ys_train.index.get_level_values('subject_id').values)\n",
    "                )\n",
    "                N_early_stop        = int(len(all_train_subjects) * early_stop_frac)\n",
    "                train_subjects      = all_train_subjects[:-N_early_stop]\n",
    "                early_stop_subjects = all_train_subjects[-N_early_stop:]\n",
    "                X_train_obs         = X_train[X_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "                Ys_train_obs        = Ys_train[Ys_train.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "                X_train_early_stop  = X_train[X_train.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "                Ys_train_early_stop = Ys_train[\n",
    "                    Ys_train.index.get_level_values('subject_id').isin(early_stop_subjects)\n",
    "                ]\n",
    "\n",
    "                train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=int(batch_size))\n",
    "                early_stop_dataloader = prepare_dataloader(\n",
    "                    X_train_early_stop, Ys_train_early_stop[t], batch_size=int(batch_size)\n",
    "                )\n",
    "                dev_dataloader        = prepare_dataloader(X_dev, Ys_dev[t], batch_size=int(batch_size))\n",
    "                test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=int(batch_size))\n",
    "\n",
    "                model_hyperparams = copy.copy(base_params)\n",
    "                model_hyperparams.update(\n",
    "                    {k: v for k, v in hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "                )\n",
    "                model = GRUD(**model_hyperparams)\n",
    "\n",
    "                best_model, _ = Train_Model(\n",
    "                    model, train_dataloader, early_stop_dataloader,\n",
    "                    **{k: v for k, v in hyperparams.items() if k in (\n",
    "                        'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "                    )}\n",
    "                )\n",
    "\n",
    "                probabilities_dev, labels_dev = predict_proba(best_model, dev_dataloader)\n",
    "                probabilities_dev = np.concatenate(probabilities_dev)[:, 1]\n",
    "                labels_dev        = np.concatenate(labels_dev)\n",
    "                s = roc_auc_score(labels_dev, probabilities_dev)\n",
    "                if s > best_s:\n",
    "                    best_s, best_hyperparams = s, hyperparams\n",
    "                    print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "                \n",
    "        ## Test\n",
    "        np.random.seed(seed)\n",
    "        hyperparams = best_hyperparams # In case I forgot a replace below\n",
    "        early_stop_frac,batch_size,seed = [best_hyperparams[k] for k in ('early_stop_frac','batch_size','seed')]\n",
    "        \n",
    "        X_train_concat, Ys_train_concat = pd.concat((X_train, X_dev)), pd.concat((Ys_train, Ys_dev))\n",
    "        \n",
    "        all_train_subjects = list(np.random.permutation(Ys_train_concat.index.get_level_values('subject_id').values))\n",
    "        N_early_stop = int(len(all_train_subjects) * early_stop_frac)\n",
    "        train_subjects, early_stop_subjects = all_train_subjects[:-N_early_stop], all_train_subjects[-N_early_stop:]\n",
    "        X_train_obs         = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "        Ys_train_obs        = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(train_subjects)]\n",
    "\n",
    "        X_train_early_stop  = X_train_concat[X_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "        Ys_train_early_stop = Ys_train_concat[Ys_train_concat.index.get_level_values('subject_id').isin(early_stop_subjects)]\n",
    "\n",
    "        train_dataloader      = prepare_dataloader(X_train_obs, Ys_train_obs[t], batch_size=batch_size)\n",
    "        early_stop_dataloader = prepare_dataloader(X_train_early_stop, Ys_train_early_stop[t], batch_size=batch_size)\n",
    "        test_dataloader       = prepare_dataloader(X_test, Ys_test[t], batch_size=batch_size)\n",
    "\n",
    "        model_hyperparams = copy.copy(base_params)\n",
    "        model_hyperparams.update(\n",
    "            {k: v for k, v in best_hyperparams.items() if k in ('cell_size', 'hidden_size', 'batch_size')}\n",
    "        )\n",
    "        model = GRUD(**model_hyperparams)\n",
    "\n",
    "        best_model, (losses_train, losses_early_stop, losses_epochs_train, losses_epochs_early_stop) = Train_Model(\n",
    "            model, train_dataloader, early_stop_dataloader,\n",
    "            **{k: v for k, v in best_hyperparams.items() if k in (\n",
    "                'num_epochs', 'patience', 'learning_rate', 'batch_size'\n",
    "            )}\n",
    "        )\n",
    "\n",
    "        probabilities_test, labels_test = predict_proba(best_model, test_dataloader)\n",
    "\n",
    "        y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "        y_pred  = np.argmax(probabilities_test)\n",
    "        y_true  = np.concatenate(labels_test)\n",
    "\n",
    "        auc   = roc_auc_score(y_true, y_score)\n",
    "        auprc = average_precision_score(y_true, y_score)\n",
    "        acc   = accuracy_score(y_true, y_pred)\n",
    "        F1    = f1_score(y_true, y_pred)\n",
    "        print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "        print(auc, auprc, acc, F1)\n",
    "        \n",
    "        results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "        with open('../src/model/extraction_baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-31T11:12:25.707766100Z"
    }
   },
   "outputs": [],
   "source": [
    "y_score = np.concatenate(probabilities_test)[:, 1]\n",
    "y_pred  = np.concatenate(probabilities_test).argmax(axis=1)\n",
    "y_true  = np.concatenate(labels_test)\n",
    "\n",
    "auc   = roc_auc_score(y_true, y_score)\n",
    "auprc = average_precision_score(y_true, y_score)\n",
    "acc   = accuracy_score(y_true, y_pred)\n",
    "F1    = f1_score(y_true, y_pred)\n",
    "print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "print(auc, auprc, acc, F1)\n",
    "\n",
    "results[model_name][t][n] = None, best_hyperparams, auc, auprc, acc, F1, best_s\n",
    "with open('../src/model/extraction_baselines_gru-d.pkl', mode='wb') as f: pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
