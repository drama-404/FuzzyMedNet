{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:15:46.098835900Z",
     "start_time": "2023-10-29T19:15:46.051447600Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:15:54.518705500Z",
     "start_time": "2023-10-29T19:15:48.507738500Z"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "import copy, math, os, pickle, time, pandas as pd, numpy as np, scipy.stats as ss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n",
    "\n",
    "import torch, torch.utils.data as utils, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from config import *\n",
    "from utils.eda_functions import (load_from_pickle, save_to_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T19:16:04.889795Z",
     "start_time": "2023-10-29T19:16:02.752110700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1f6c86b3830>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DATA_FILEPATH     = '/scratch/mmd/mimic_data/final/grouping_5/all_hourly_data.h5'\n",
    "# RAW_DATA_FILEPATH = '/scratch/mmd/mimic_data/final/nogrouping_5/all_hourly_data.h5'\n",
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 1\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:16:06.636857500Z",
     "start_time": "2023-10-29T19:16:06.488000500Z"
    }
   },
   "outputs": [],
   "source": [
    "class DictDist():\n",
    "    def __init__(self, dict_of_rvs): self.dict_of_rvs = dict_of_rvs\n",
    "    def rvs(self, n):\n",
    "        a = {k: v.rvs(n) for k, v in self.dict_of_rvs.items()}\n",
    "        out = []\n",
    "        for i in range(n): out.append({k: vs[i] for k, vs in a.items()})\n",
    "        return out\n",
    "    \n",
    "class Choice():\n",
    "    def __init__(self, options): self.options = options\n",
    "    def rvs(self, n): return [self.options[i] for i in ss.randint(0, len(self.options)).rvs(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train = load_from_pickle(os.path.join(DATA_DIR, 'Vitals_train.pkl'))\n",
    "X_dev = load_from_pickle(os.path.join(DATA_DIR, 'Vitals_dev.pkl'))\n",
    "X_test = load_from_pickle(os.path.join(DATA_DIR, 'Vitals_test.pkl'))\n",
    "\n",
    "Ys_train = load_from_pickle(os.path.join(DATA_DIR, 'Y_train.pkl'))\n",
    "Ys_dev = load_from_pickle(os.path.join(DATA_DIR, 'Y_dev.pkl'))\n",
    "Ys_test = load_from_pickle(os.path.join(DATA_DIR, 'Y_test.pkl'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:16:38.111245Z",
     "start_time": "2023-10-29T19:16:37.001684200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "        X_train, X_dev, X_test\n",
    "    )\n",
    "]\n",
    "lvl2_flat_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# data_full_lvl2 = pd.read_hdf(DATA_FILEPATH, 'vitals_labs')\n",
    "# data_full_raw  = pd.read_hdf(RAW_DATA_FILEPATH, 'vitals_labs') \n",
    "# statics        = pd.read_hdf(DATA_FILEPATH, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_full_lvl2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_full_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# statics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def simple_imputer(df):\n",
    "#     idx = pd.IndexSlice\n",
    "#     df = df.copy()\n",
    "#     if len(df.columns.names) > 2: df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "#     \n",
    "#     df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "#     icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "#     \n",
    "#     df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "#         method='ffill'\n",
    "#     ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "#     \n",
    "#     df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "#     df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "#     \n",
    "#     is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "#     hours_of_absence = is_absent.cumsum()\n",
    "#     time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "#     time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "# \n",
    "#     df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "#     df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "#     \n",
    "#     df_out.sort_index(axis=1, inplace=True)\n",
    "#     return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "# Ys['los_3'] = Ys['los_icu'] > 3\n",
    "# Ys['los_7'] = Ys['los_icu'] > 7\n",
    "# Ys.drop(columns=['los_icu'], inplace=True)\n",
    "# Ys.astype(float)\n",
    "# \n",
    "# lvl2, raw = [df[\n",
    "#     (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "#     (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "# ] for df in (data_full_lvl2, data_full_raw)]\n",
    "# \n",
    "# raw.columns = raw.columns.droplevel(level=['label', 'LEVEL1', 'LEVEL2'])\n",
    "# \n",
    "# train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "# lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "# lvl2_subjects = set(lvl2_subj_idx)\n",
    "# assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "# assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\"\n",
    "# \n",
    "# np.random.seed(SEED)\n",
    "# subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "# N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "# train_subj = subjects[:N_train]\n",
    "# dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "# test_subj  = subjects[N_train+N_dev:]\n",
    "# \n",
    "# [(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "#     [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "#     for df in (lvl2, raw, Ys)\n",
    "# ]\n",
    "# \n",
    "# idx = pd.IndexSlice\n",
    "# lvl2_means, lvl2_stds = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0), lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "# raw_means, raw_stds = raw_train.loc[:, idx[:,'mean']].mean(axis=0), raw_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "# \n",
    "# lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "# lvl2_dev.loc[:, idx[:,'mean']] = (lvl2_dev.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "# lvl2_test.loc[:, idx[:,'mean']] = (lvl2_test.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "# \n",
    "# raw_train.loc[:, idx[:,'mean']] = (raw_train.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "# raw_dev.loc[:, idx[:,'mean']] = (raw_dev.loc[:, idx[:,'mean']] - raw_means)/raw_stds\n",
    "# raw_test.loc[:, idx[:,'mean']] = (raw_test.loc[:, idx[:,'mean']] - raw_means)/raw_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test = [\n",
    "#     simple_imputer(df) for df in (raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test)\n",
    "# ]\n",
    "# raw_flat_train, raw_flat_dev, raw_flat_test, lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "#     df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "#         raw_train, raw_dev, raw_test, lvl2_train, lvl2_dev, lvl2_test\n",
    "#     )\n",
    "# ]\n",
    "# \n",
    "# for df in lvl2_train, lvl2_dev, lvl2_test, raw_train, raw_dev, raw_test: assert not df.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:16:47.307011700Z",
     "start_time": "2023-10-29T19:16:47.134791700Z"
    }
   },
   "outputs": [],
   "source": [
    "N = 15\n",
    "\n",
    "LR_dist = DictDist({\n",
    "    'C': Choice(np.geomspace(1e-3, 1e3, 10000)),\n",
    "    'penalty': Choice(['l1', 'l2']),\n",
    "    'solver': Choice(['liblinear', 'lbfgs']),\n",
    "    'max_iter': Choice([100, 500])\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "LR_hyperparams_list = LR_dist.rvs(N)\n",
    "for i in range(N):\n",
    "    if LR_hyperparams_list[i]['solver'] == 'lbfgs': LR_hyperparams_list[i]['penalty'] = 'l2'\n",
    "\n",
    "RF_dist = DictDist({\n",
    "    'n_estimators': ss.randint(50, 500),\n",
    "    'max_depth': ss.randint(2, 10),\n",
    "    'min_samples_split': ss.randint(2, 75),\n",
    "    'min_samples_leaf': ss.randint(1, 50),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "RF_hyperparams_list = RF_dist.rvs(N)\n",
    "\n",
    "GRU_D_dist = DictDist({\n",
    "    'cell_size': ss.randint(50, 75),\n",
    "    'hidden_size': ss.randint(65, 95), \n",
    "    'learning_rate': ss.uniform(2e-3, 1e-1),\n",
    "    'num_epochs': ss.randint(15, 150),\n",
    "    'patience': ss.randint(3, 7),\n",
    "    'batch_size': ss.randint(35, 65),\n",
    "    'early_stop_frac': ss.uniform(0.05, 0.1),\n",
    "    'seed': ss.randint(1, 10000),\n",
    "})\n",
    "np.random.seed(SEED)\n",
    "GRU_D_hyperparams_list = GRU_D_dist.rvs(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:16:50.804786700Z",
     "start_time": "2023-10-29T19:16:50.659044100Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_basic(model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, target):\n",
    "    best_s, best_hyperparams = -np.Inf, None\n",
    "    for i, hyperparams in enumerate(hyperparams_list):\n",
    "        print(\"On sample %d / %d (hyperparams = %s)\" % (i+1, len(hyperparams_list), repr((hyperparams))))\n",
    "        M = model(**hyperparams)\n",
    "        M.fit(X_flat_train, Ys_train[target])\n",
    "        s = roc_auc_score(Ys_dev[target], M.predict_proba(X_flat_dev)[:, 1])\n",
    "        if s > best_s:\n",
    "            best_s, best_hyperparams = s, hyperparams\n",
    "            print(\"New Best Score: %.2f @ hyperparams = %s\" % (100*best_s, repr((best_hyperparams))))\n",
    "\n",
    "    return run_only_final(model, best_hyperparams, X_flat_train, X_flat_dev, X_flat_test, target)\n",
    "\n",
    "def run_only_final(model, best_hyperparams, X_flat_train, X_flat_dev, X_flat_test, target):\n",
    "    best_M = model(**best_hyperparams)\n",
    "    best_M.fit(pd.concat((X_flat_train, X_flat_dev)), pd.concat((Ys_train, Ys_dev))[target])\n",
    "    y_true  = Ys_test[target]\n",
    "    y_score = best_M.predict_proba(X_flat_test)[:, 1]\n",
    "    y_pred  = best_M.predict(X_flat_test)\n",
    "\n",
    "    auc   = roc_auc_score(y_true, y_score)\n",
    "    auprc = average_precision_score(y_true, y_score)\n",
    "    acc   = accuracy_score(y_true, y_pred)\n",
    "    F1    = f1_score(y_true, y_pred)\n",
    "    \n",
    "    return best_M, best_hyperparams, auc, auprc, acc, F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-29T19:26:06.374202200Z",
     "start_time": "2023-10-29T19:26:06.222878Z"
    }
   },
   "outputs": [],
   "source": [
    "RESULTS_PATH = '../model/baselines-sklearn.pkl'\n",
    "# with open(RESULTS_PATH, mode='rb') as f: results = pickle.load(f)\n",
    "results = {}   \n",
    "RERUN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T19:43:17.346300300Z",
     "start_time": "2023-10-29T19:26:10.097856400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model RF on target mort_hosp with representation lvl2\n",
      "On sample 1 / 15 (hyperparams = {'n_estimators': 87, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 8})\n",
      "New Best Score: 79.29 @ hyperparams = {'n_estimators': 87, 'max_depth': 3, 'min_samples_split': 15, 'min_samples_leaf': 8}\n",
      "On sample 2 / 15 (hyperparams = {'n_estimators': 285, 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 4})\n",
      "New Best Score: 80.88 @ hyperparams = {'n_estimators': 285, 'max_depth': 4, 'min_samples_split': 11, 'min_samples_leaf': 4}\n",
      "On sample 3 / 15 (hyperparams = {'n_estimators': 446, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7})\n",
      "New Best Score: 82.86 @ hyperparams = {'n_estimators': 446, 'max_depth': 6, 'min_samples_split': 9, 'min_samples_leaf': 7}\n",
      "On sample 4 / 15 (hyperparams = {'n_estimators': 122, 'max_depth': 8, 'min_samples_split': 65, 'min_samples_leaf': 22})\n",
      "New Best Score: 83.38 @ hyperparams = {'n_estimators': 122, 'max_depth': 8, 'min_samples_split': 65, 'min_samples_leaf': 22}\n",
      "On sample 5 / 15 (hyperparams = {'n_estimators': 305, 'max_depth': 7, 'min_samples_split': 63, 'min_samples_leaf': 4})\n",
      "On sample 6 / 15 (hyperparams = {'n_estimators': 443, 'max_depth': 4, 'min_samples_split': 24, 'min_samples_leaf': 5})\n",
      "On sample 7 / 15 (hyperparams = {'n_estimators': 253, 'max_depth': 6, 'min_samples_split': 59, 'min_samples_leaf': 25})\n",
      "On sample 8 / 15 (hyperparams = {'n_estimators': 183, 'max_depth': 5, 'min_samples_split': 3, 'min_samples_leaf': 44})\n",
      "On sample 9 / 15 (hyperparams = {'n_estimators': 385, 'max_depth': 6, 'min_samples_split': 2, 'min_samples_leaf': 13})\n",
      "On sample 10 / 15 (hyperparams = {'n_estimators': 498, 'max_depth': 4, 'min_samples_split': 62, 'min_samples_leaf': 27})\n",
      "On sample 11 / 15 (hyperparams = {'n_estimators': 194, 'max_depth': 6, 'min_samples_split': 10, 'min_samples_leaf': 17})\n",
      "On sample 12 / 15 (hyperparams = {'n_estimators': 179, 'max_depth': 7, 'min_samples_split': 15, 'min_samples_leaf': 46})\n",
      "On sample 13 / 15 (hyperparams = {'n_estimators': 121, 'max_depth': 8, 'min_samples_split': 49, 'min_samples_leaf': 42})\n",
      "On sample 14 / 15 (hyperparams = {'n_estimators': 287, 'max_depth': 4, 'min_samples_split': 74, 'min_samples_leaf': 19})\n",
      "On sample 15 / 15 (hyperparams = {'n_estimators': 440, 'max_depth': 6, 'min_samples_split': 32, 'min_samples_leaf': 16})\n",
      "Final results for model RF on target mort_hosp with representation lvl2\n",
      "(0.8481686153981979, 0.47431834470382245, 0.8993526832324076, 0.11397058823529413)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../model/baselines-sklearn.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal results for model \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m on target \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m with representation \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (model_name, t, n))\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28mprint\u001B[39m(results[model_name][t][n][\u001B[38;5;241m2\u001B[39m:])\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(RESULTS_PATH, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f: pickle\u001B[38;5;241m.\u001B[39mdump(results, f)\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:286\u001B[0m, in \u001B[0;36m_modified_open\u001B[1;34m(file, *args, **kwargs)\u001B[0m\n\u001B[0;32m    279\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[0;32m    280\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    281\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    282\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    283\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    284\u001B[0m     )\n\u001B[1;32m--> 286\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m io_open(file, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '../model/baselines-sklearn.pkl'"
     ]
    }
   ],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "    ('RF', RandomForestClassifier, RF_hyperparams_list), ('LR', LogisticRegression, LR_hyperparams_list)\n",
    "]:\n",
    "    if model_name not in results: results[model_name] = {}\n",
    "    for t in ['mort_hosp']:\n",
    "        if t not in results[model_name]: results[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "            ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "            # ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)\n",
    "        ):\n",
    "            if n in results[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results[model_name][t][n][1]\n",
    "                    results[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results[model_name][t][n][2:])\n",
    "\n",
    "                    with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results[model_name][t][n][2:])\n",
    "            with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(SEED+1)\n",
    "LR_hyperparams_list_2 = LR_dist.rvs(45)\n",
    "for i in range(45):\n",
    "    if LR_hyperparams_list_2[i]['solver'] == 'lbfgs': LR_hyperparams_list_2[i]['penalty'] = 'l2'\n",
    "\n",
    "results_2 = {}\n",
    "results_2_PATH = '/scratch/mmd/extraction_baselines-sklearn_LR_2_runs.pkl'\n",
    "\n",
    "for model_name, model, hyperparams_list in [\n",
    "#     ('RF', RandomForestClassifier, RF_hyperparams_list),\n",
    "    ('LR', LogisticRegression, LR_hyperparams_list_2)\n",
    "]:\n",
    "    if model_name not in results_2: results_2[model_name] = {}\n",
    "    for t in ['mort_icu', 'los_3']:\n",
    "        if t not in results_2[model_name]: results_2[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "            ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "#             ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)\n",
    "        ):\n",
    "            if n in results_2[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results_2[model_name][t][n][1]\n",
    "                    results_2[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results_2[model_name][t][n][2:])\n",
    "\n",
    "                    with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results_2[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results_2[model_name][t][n][2:])\n",
    "            with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "#     ('RF', RandomForestClassifier, RF_hyperparams_list),\n",
    "    ('LR', LogisticRegression, LR_hyperparams_list_2)\n",
    "]:\n",
    "    if model_name not in results_2: results_2[model_name] = {}\n",
    "    for t in ['mort_icu', 'los_3']:\n",
    "        if t not in results_2[model_name]: results_2[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "#             ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "            ('raw', raw_flat_train, raw_flat_dev, raw_flat_test),\n",
    "        ):\n",
    "            if n in results_2[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results_2[model_name][t][n][1]\n",
    "                    results_2[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results_2[model_name][t][n][2:])\n",
    "\n",
    "                    with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results_2[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results_2 for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results_2[model_name][t][n][2:])\n",
    "            with open(results_2_PATH, mode='wb') as f: pickle.dump(results_2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for model_name, model, hyperparams_list in [\n",
    "    ('RF', RandomForestClassifier, RF_hyperparams_list), ('LR', LogisticRegression, LR_hyperparams_list)\n",
    "]:\n",
    "    if model_name not in results: results[model_name] = {}\n",
    "    for t in ['mort_hosp', 'los_7']:\n",
    "        if t not in results[model_name]: results[model_name][t] = {}\n",
    "        for n, X_flat_train, X_flat_dev, X_flat_test in (\n",
    "            ('lvl2', lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test),\n",
    "            ('raw', raw_flat_train, raw_flat_dev, raw_flat_test)\n",
    "        ):\n",
    "            if n in results[model_name][t]:\n",
    "                print(\"Finished model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                if RERUN: \n",
    "                    h = results[model_name][t][n][1]\n",
    "                    results[model_name][t][n] = run_only_final(model, h, X_flat_train, X_flat_dev, X_flat_test, t)\n",
    "                    \n",
    "                    print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "                    print(results[model_name][t][n][2:])\n",
    "\n",
    "                    with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)\n",
    "                continue\n",
    "                \n",
    "            print(\"Running model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            results[model_name][t][n] = run_basic(\n",
    "                model, hyperparams_list, X_flat_train, X_flat_dev, X_flat_test, t\n",
    "            )\n",
    "            print(\"Final results for model %s on target %s with representation %s\" % (model_name, t, n))\n",
    "            print(results[model_name][t][n][2:])\n",
    "            with open(RESULTS_PATH, mode='wb') as f: pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
